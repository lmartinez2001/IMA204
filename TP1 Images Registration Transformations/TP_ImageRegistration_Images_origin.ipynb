{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_ImageRegistration_Images.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xds_hMNdW-t4"
      },
      "source": [
        "## Image registration\n",
        "\n",
        "**Deadline**: Upload this notebook (rename it as 'TP-ImageRegistration-Images-YOUR-SURNAME.ipynb') to E-Campus before the deadline (see E-campus for the exact timing).\n",
        "\n",
        "**Goal**: The goal of this notebook is to implement the algorithms seen today for pixel-based image registration. Please complete the code where you see **XXXXXXXXXXXXXX**\n",
        "\n",
        "You will first take two pictures of your right hand into two different positions. Please keep the same topology, ie do not bend or stick together two fingers for instance. \n",
        "\n",
        "If you can't take the pictures, you can use two pictures of my hand (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "045P71XHW2QK"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id='1XpgGRo839pBwIhb6h77xoG-NtHEg2DVd',\n",
        "  dest_path='./Source.jpg')\n",
        "\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id='12FKfLjKreAksI3rEcDx4_oEn3qjAzEua',\n",
        "  dest_path='./Target.jpg')\n",
        "else:\n",
        "  print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data')\n",
        "\n",
        "# Please modify working_dir only if you are using your Anaconda (and not Google Colab)\n",
        "# You should write the absolute path of your working directory with the data\n",
        "workingDir='./'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UHXY9l4uJHZ"
      },
      "source": [
        "We will use the skimage library to read and resize images, you can of course use others (openCV, pillow, scipy, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj93jNYXXmUC"
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        "import numpy as np\n",
        "import scipy.ndimage"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU6vsAl_uyPl"
      },
      "source": [
        "The first thing to do is to create a function that creates the transformation matrix T. Please complete the following function following the rules explained in the header of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H44C9mFgXpsj"
      },
      "source": [
        "def Tmatrix(scale=(1,1), rotationAngle=0, shearAngles=(0,0),translation=(0,0),elation=(0,0),reflection=(False,False)):\n",
        "    ''' \n",
        "    Transformation matrix defined as the composition of 6 possible geometric\n",
        "    transformations: Reflection (Re), Rotation (R), Scaling (S), Shear (Sh),\n",
        "    Translation (T) and Elation (E).\n",
        "    For the linear transformation part, we assume this composition: \n",
        "        A = Re * R * S * Sh\n",
        "        \n",
        "    Inputs: \n",
        "            scale: is a tuple with sx and sy (two scalar values)\n",
        "            rotationAngle: is an angle in degrees (scalar value)\n",
        "            shearAngles: is a tuple with the two shear angles in degrees (scalar value)\n",
        "            translation: is a tuple with tx and ty (scalar values)\n",
        "            elation: is a tuple containing the elation part (scalar values)\n",
        "            reflection: is a tuple of Boolean values indicating wheter to reflect with respect to x and y axis\n",
        "            \n",
        "    Output:\n",
        "            T: the 3x3 transformation matrix (homogeneous coordinates)\n",
        "    '''    \n",
        "    \n",
        "    if len(scale) != 2:\n",
        "        raise ValueError(\"scale should be a tuple of length 2\")\n",
        "    if len(shearAngles)!= 2:\n",
        "        raise ValueError(\"shearAngles should be a tuple of length 2\")\n",
        "    if len(translation)!= 2:\n",
        "        raise ValueError(\"translation should be a tuple of length 2\")\n",
        "    if len(elation)!= 2:\n",
        "        raise ValueError(\"elation should be a tuple of length 2\")\n",
        "    if len(reflection)!= 2:\n",
        "        raise ValueError(\"reflection should be a tuple of length 2\")\n",
        "    if type(reflection[0])!= bool or type(reflection[1]) != bool:\n",
        "        raise ValueError(\"reflection should contain two boolean values\")       \n",
        "    if np.ndim(rotationAngle) != 0:\n",
        "        raise ValueError(\"rotationAngle should be a scalar\")\n",
        "        \n",
        "    # transform angles from degrees to radians    \n",
        "    XXXXXXXXXXXXXX\n",
        "   \n",
        "    # compute T       \n",
        "    T =XXXXXXXXXXXXXX\n",
        "              \n",
        "    return T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLWF97TRvsVo"
      },
      "source": [
        "Test here, your function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSys_7HXvxyv"
      },
      "source": [
        "## Define Transformation\n",
        "T=Tmatrix(scale=(1,1), rotationAngle=40, shearAngles=(0,0),translation=(0,0),elation=(0,0),reflection=(False,False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4OooGlqvYJp"
      },
      "source": [
        "Next, we need to create a function that apply the previously created transformation matrix. We will need to apply it either to 2D points, seen as a [Nx2] numpy array where N is the number of points, or to image coordinates, modeled as a [2xNxM] Numpy array where N and M are the number of rows and columns of the image respectively. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIC03QfVX27g"
      },
      "source": [
        "def applyTransformation(T, points=None, coords=None):\n",
        "    ''' \n",
        "    Apply geometric transformation to points or image coordinates.\n",
        "    Transformation is defined by a 3x3 matrix\n",
        "        \n",
        "    Inputs: \n",
        "        points: Nx2 Numpy array of points \n",
        "        coordinates: 2xNxM Numpy array of image coordinates\n",
        "        T: 3x3 matrix trasformation\n",
        "            \n",
        "    Output:\n",
        "        pm: Nx2 points after transformation\n",
        "        cm: 2xNxM image coordinates after transformation\n",
        "    ''' \n",
        "    if points is None and coords is None:\n",
        "        raise ValueError(\"Error ! You should provide points and/or coords\")\n",
        "    \n",
        "    if points is not None:    \n",
        "        N,d = points.shape\n",
        "        if d != 2 and N==2:\n",
        "            print('WARNING ! points should be an array of dimension Nx2'+\n",
        "                  ' Transposing the array')\n",
        "            points=points.T\n",
        "            N,d = points.shape\n",
        "            \n",
        "        if d != 2:\n",
        "            raise ValueError(\"Error ! Function works only with 2D points\")\n",
        "            \n",
        "        # Transform points into homogeneous coordinates (adding one...)\n",
        "        XXXXXXXXXXXXXX\n",
        "        \n",
        "        # Apply transformation\n",
        "        XXXXXXXXXXXXXX\n",
        "        \n",
        "        # If homography, ...\n",
        "        XXXXXXXXXXXXXX\n",
        "\n",
        "        pm=XXXXXXXXXXXXXX\n",
        "    else:\n",
        "        pm=None\n",
        "        \n",
        "    if coords is not None:\n",
        "        d,N,M = coords.shape\n",
        "        \n",
        "        if d != 2:\n",
        "            raise ValueError(\"Error ! Function works only with 2D coordinates\")\n",
        "        \n",
        "        p = coords.reshape((2,N*M)).T # reshape coordinates as list of points\n",
        "        # Transform points into homogeneous coordinates (adding one...)\n",
        "        XXXXXXXXXXXXXX\n",
        "        \n",
        "        # Apply transformation\n",
        "        XXXXXXXXXXXXXX\n",
        "        \n",
        "        # If homography, ...\n",
        "        pm=XXXXXXXXXXXXXX\n",
        "        cm = pm.reshape((2,N,M))\n",
        "        \n",
        "    else:\n",
        "        cm =None\n",
        "                \n",
        "    return pm,cm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFiD3xbuwgNB"
      },
      "source": [
        "Now, we can test the two functions on some data-sets of 2D points. To keep things simple, you will create two data-sets of points.\n",
        "\n",
        "In the first one, the points will draw an ellipse (ie uniform sampling on an ellipse).\n",
        "In the secon data-set, the points will draw a square (ie uniform sampling on a square).\n",
        "\n",
        "You will then try several (at least five) different trasformations and check if your code works well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3bOJh7gdCzm"
      },
      "source": [
        "# Ellipse\n",
        "theta = np.deg2rad(np.arange(0.0, 360.0, 1.0))\n",
        "x = XXXXXXXXXXXXXX\n",
        "y = XXXXXXXXXXXXXX\n",
        "points=np.array([x, y]).T\n",
        "\n",
        "## Define Transformation\n",
        "T=Tmatrix(scale=(1,1), rotationAngle=40, shearAngles=(0,0),translation=(0,0),elation=(0,0),reflection=(False,False))\n",
        "\n",
        "## Apply trasformation\n",
        "moved = applyTransformation(T, points=points)[0]\n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "ax1.scatter(points[:,0],points[:,1])\n",
        "ax2.scatter(moved[:,0],moved[:,1])\n",
        "\n",
        "minimum = np.min((ax1.get_xlim(),ax1.get_ylim(),ax2.get_xlim(),ax2.get_ylim()))\n",
        "maximum = np.max((ax1.get_xlim(),ax1.get_ylim(),ax2.get_xlim(),ax2.get_ylim()))\n",
        "\n",
        "ax1.set_xlim(minimum*1.2,maximum*1.2)\n",
        "ax1.set_ylim(minimum*1.2,maximum*1.2)\n",
        "ax2.set_xlim(minimum*1.2,maximum*1.2)\n",
        "ax2.set_ylim(minimum*1.2,maximum*1.2)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB6OuCTjdSXk"
      },
      "source": [
        "# Square\n",
        "x=XXXXXXXXXXXXXX\n",
        "y=XXXXXXXXXXXXXX\n",
        "points=np.array([x,y]).T\n",
        "\n",
        "## Define Transformation\n",
        "T=Tmatrix(scale=(1,1), rotationAngle=40, shearAngles=(0,0),translation=(0,0),elation=(0,0),reflection=(False,False))\n",
        "\n",
        "## Apply trasformation\n",
        "moved = applyTransformation(T, points=points)[0]\n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "ax1.scatter(points[:,0],points[:,1])\n",
        "ax2.scatter(moved[:,0],moved[:,1])\n",
        "\n",
        "minimum = np.min((ax1.get_xlim(),ax1.get_ylim(),ax2.get_xlim(),ax2.get_ylim()))\n",
        "maximum = np.max((ax1.get_xlim(),ax1.get_ylim(),ax2.get_xlim(),ax2.get_ylim()))\n",
        "\n",
        "ax1.set_xlim(minimum*1.2,maximum*1.2)\n",
        "ax1.set_ylim(minimum*1.2,maximum*1.2)\n",
        "ax2.set_xlim(minimum*1.2,maximum*1.2)\n",
        "ax2.set_ylim(minimum*1.2,maximum*1.2)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TA21Jv5xum6"
      },
      "source": [
        "Now, we can finally move to images. Here, you can load and plot the two images of your (or mine) right hand. Pixel intensities are normalized in order to be float between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oDkrIhsxXU1"
      },
      "source": [
        "SourceIm = imread(workingDir + 'Source.jpg', as_gray=True)\n",
        "SourceImNorm=(SourceIm - np.amin(SourceIm)) / (np.amax(SourceIm) - np.amin(SourceIm))\n",
        "TargetIm = imread(workingDir + 'Target.jpg', as_gray=True)\n",
        "TargetImNorm=(TargetIm - np.amin(TargetIm)) / (np.amax(TargetIm) - np.amin(TargetIm))\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "ax1.imshow(SourceImNorm, cmap='gray')\n",
        "ax1.set_title('Source image')\n",
        "ax2.imshow(TargetImNorm, cmap='gray')\n",
        "ax2.set_title('Target image')\n",
        "plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXWkdVR0yUyl"
      },
      "source": [
        "In the following function, you will code the forward warping technique with point splatting. \n",
        "\n",
        "Theoretically, an image could be associated with a coordinate chart giving the real-world coordinates of each pixel. However, the problem becomes more difficult and in many applications we do not actually have this coordinate chart. Here, you will simply consider the coordinate of a pixel as its row and column position.\n",
        "\n",
        "In the forward warping, as seen during the lecture of this morning, the coordinates of a pixel of a source image $I$ might not be warped exactly onto the output grid. When it falls within the grid, but not on the grid, we assign (ie splat) the pixel intensity of $I$ to the four neighbour 'corners' of the output grid. \n",
        "\n",
        "These contributions must be weighted and for this reason a typical solution is to create an 'accumulator'. This is an array of the same size of the output grid which quantifies the number of contributions that each corner of the output grid has received. By simply dividing by the number of contributions (output grid ./ accumulator), we obtain at each corner of the output grid an averaged estimate of the intensity of the transformed image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMFrV5dOX3YL"
      },
      "source": [
        "def ForwardWarping(I,T,coords=None,outputShape=None):\n",
        "    ''' \n",
        "    Apply forward warping to an image I based on a transformation T.\n",
        "    Transformation is defined by a 3x3 matrix T\n",
        "        \n",
        "    Inputs: \n",
        "        I: image to transform\n",
        "        T: 3x3 matrix trasformation\n",
        "        coords: coordinates of the image. If None, the coordinates of a pixel\n",
        "                are automatically its row and column position\n",
        "        outputShape: defines the shape of the transformed image.\n",
        "                     It can be 'None', same shape as the input image I or 'BB', \n",
        "                     bounding box of the transformed image I_T,  or a tuple/numpy\n",
        "                     array with 4 elements (min x, max x, min y, max y)\n",
        "                    \n",
        "    Output:\n",
        "        J: transformed image\n",
        "    ''' \n",
        "\n",
        "    if coords is None:\n",
        "      coords = np.mgrid[0:I.shape[0], 0:I.shape[1]] # coordinates of the image I\n",
        "      cm = applyTransformation(T,coords=coords)[1]\n",
        "\n",
        "      if outputShape is None:\n",
        "          outputShape=(0,I.shape[0],0,I.shape[1])\n",
        "          \n",
        "      elif outputShape == 'BB':\n",
        "          #Find extremities bounding box\n",
        "          bx=int(np.floor(np.min(cm[0,:,:])))\n",
        "          ux=int(np.ceil(np.max(cm[0,:,:])))\n",
        "          by=int(np.floor(np.min(cm[1,:,:])))\n",
        "          uy=int(np.ceil(np.max(cm[1,:,:])))\n",
        "          outputShape=(bx,ux,by,uy)\n",
        "          \n",
        "      elif isinstance(outputShape, tuple):\n",
        "          if len(outputShape) != 4:\n",
        "              raise ValueError(\"Error ! outputShape should be of length 4\")           \n",
        "              \n",
        "      elif isinstance(outputShape, np.ndarray):\n",
        "          if len(outputShape) != 4:\n",
        "              raise ValueError(\"Error ! outputShape should be of length 4\")                                      \n",
        "      else:\n",
        "          raise ValueError(\"Error ! outputShape should be None, 'BB' or a tuple/numpy array with 4 elements\")       \n",
        "                                \n",
        "      J= XXXXXXXXXXXXXX # transformed image\n",
        "      acc= XXXXXXXXXXXXXX # accumulator\n",
        "\n",
        "      for i in range(XXXXXXXXXXXXXX):\n",
        "          for j in range(XXXXXXXXXXXXXX):\n",
        "              \n",
        "              # transformed coordinate of a pixel\n",
        "              p=cm[:,i,j]\n",
        "              x=p[0]\n",
        "              y=p[1]\n",
        "              \n",
        "              # Check if point is inside outputShape\n",
        "              if XXXXXXXXXXXXXX:\n",
        "                            \n",
        "                  # translate if necessary, since output image will start from (0,0)                         \n",
        "                  # it basically shifts transformed points in the positive quadrant\n",
        "                  if outputShape[0]<0:\n",
        "                      x=x+abs(outputShape[0])\n",
        "                      \n",
        "                  if outputShape[2]<0:\n",
        "                      y=y+abs(outputShape[2])   \n",
        "                  \n",
        "                  # Look for the four corners\n",
        "                  bl=( XXXXXXXXXXXXXX, XXXXXXXXXXXXXX ) # bottom left\n",
        "                  br=( XXXXXXXXXXXXXX, XXXXXXXXXXXXXX ) # bottom right\n",
        "                  ul=( XXXXXXXXXXXXXX, XXXXXXXXXXXXXX ) # up left\n",
        "                  ur=( XXXXXXXXXXXXXX, XXXXXXXXXXXXXX ) # up right\n",
        "                  \n",
        "                  # Update J and acc\n",
        "                  XXXXXXXXXXXXXX\n",
        "\n",
        "      acc[acc==0]=1        \n",
        "      J=np.divide(J,acc)\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\"Error ! Still not implemented\")\n",
        "        \n",
        "    return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5hvscuOGVa7"
      },
      "source": [
        "Let's test your implementation of the forward warping with the right hand image. Test with at least 5 different transformation matrices (try different configurations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fs4H0BGgNm"
      },
      "source": [
        "# Resize image (to make it faster...)\n",
        "X= resize(SourceImNorm, (250,250), anti_aliasing=True)\n",
        "T=Tmatrix(scale=(1,1), rotationAngle=0, shearAngles=(45,37),translation=(0,0),elation=(0,0),reflection=(False,False))\n",
        "print('The transformation matrix T is:\\n', T)\n",
        "\n",
        "Xmf=ForwardWarping(X,T,outputShape=None)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "ax1.imshow(X, cmap='gray')\n",
        "ax1.set_title('Source image')\n",
        "ax2.imshow(Xmf, cmap='gray')\n",
        "ax2.set_title('Forward warped image')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6e073EAG1yy"
      },
      "source": [
        "Now, we can implement the Inverse Warping (what is usually used as seen this morning).\n",
        "\n",
        "As before, you will not use external coordinates, the coordinates of a pixel will be its row and column position.\n",
        "\n",
        "For the interpolation step, you will implement and use the nearest neighbour tehcnique but you can implement and use otherw (e.g. bilinear, cubic, etc.) if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Mylx7QX8WJ"
      },
      "source": [
        "def nearestNeighboutInterp(pM,I,coords=None):\n",
        "    ''' \n",
        "    Nearest Neighbout interpolation\n",
        "        \n",
        "    Inputs: \n",
        "        pM: 2D point defining the coordinates to interpolate\n",
        "        I: image used for interpolation\n",
        "        coords: coordinates of the image. If None, the coordinates of a pixel\n",
        "                are automatically its row and column position\n",
        "                    \n",
        "    Output:\n",
        "        value: interpolated value at pM\n",
        "    ''' \n",
        "    \n",
        "    if coords is None:\n",
        "        # row and column of pM\n",
        "        r = XXXXXXXXXXXXXX\n",
        "        c = XXXXXXXXXXXXXX\n",
        "        \n",
        "        # check if r and c are within the domain of I (I.shape)\n",
        "        if XXXXXXXXXXXXXX:\n",
        "                value = XXXXXXXXXXXXXX\n",
        "        else:\n",
        "            value=0\n",
        "        \n",
        "    else:\n",
        "        raise ValueError(\"Error ! Still not implemented\")\n",
        "        value=0\n",
        "        \n",
        "    return value\n",
        "\n",
        "def InverseWarping(I,T,coords=None,outputShape=None):\n",
        "    ''' \n",
        "    Apply inverse warping to an image I based on a transformation T.\n",
        "    Transformation is defined by a 3x3 matrix\n",
        "        \n",
        "    Inputs: \n",
        "        I: image to transform\n",
        "        T: 3x3 matrix trasformation\n",
        "        coords: coordinates of the image. If None, the coordinates of a pixel\n",
        "                are automatically its row and column position\n",
        "        outputShape: defines the shape of the transformed image.\n",
        "                     It can be 'None', same shape as the input image I or 'BB', \n",
        "                     bounding box of the transformed image I_T,  or a tuple/numpy\n",
        "                     array with 4 elements (min x, max x, min y, max y)\n",
        "        \n",
        "            \n",
        "    Output:\n",
        "        J: transformed image\n",
        "    ''' \n",
        "    \n",
        "    if coords is None:\n",
        "        \n",
        "        if outputShape is None:\n",
        "            outputShape=(0,I.shape[0],0,I.shape[1])\n",
        "            \n",
        "        elif outputShape == 'BB':\n",
        "            coords = np.mgrid[0:I.shape[0], 0:I.shape[1]] # coordinates\n",
        "            cm = applyTransformation(T,coords=coords)[1]\n",
        "            #Find extremities bounding box\n",
        "            bx=int(np.floor(np.min(cm[0,:,:])))\n",
        "            ux=int(np.ceil(np.max(cm[0,:,:])))\n",
        "            by=int(np.floor(np.min(cm[1,:,:])))\n",
        "            uy=int(np.ceil(np.max(cm[1,:,:])))\n",
        "            outputShape=(bx,ux,by,uy)\n",
        "            \n",
        "        elif isinstance(outputShape, tuple):\n",
        "            if len(outputShape) != 4:\n",
        "                raise ValueError(\"Error ! outputShape should be of length 4\")           \n",
        "                \n",
        "        elif isinstance(outputShape, np.ndarray):\n",
        "            if len(outputShape) != 4:\n",
        "                raise ValueError(\"Error ! outputShape should be of length 4\")                                      \n",
        "        else:\n",
        "            raise ValueError(\"Error ! outputShape should be None, 'BB' or a tuple/numpy array with 4 elements\")       \n",
        "                                 \n",
        "        J= XXXXXXXXXXXXXX # transformed image\n",
        "        \n",
        "        for i in range(XXXXXXXXXXXXXX]):\n",
        "            for j in range(XXXXXXXXXXXXXX):\n",
        "\n",
        "                p=XXXXXXXXXXXXXX # coordinate of a pixel to transform\n",
        "                pM = XXXXXXXXXXXXXX # transformed coordinate\n",
        "\n",
        "                if pM[-1] != 0: \n",
        "                  pM = XXXXXXXXXXXXXX # normalization in case of homography\n",
        "\n",
        "                  # shifting since the first pixel will be in (0,0) in the output image\n",
        "                  if outputShape[0]<0:\n",
        "                      x=i+abs(outputShape[0])\n",
        "                  else:\n",
        "                      x=i\n",
        "                  if outputShape[2]<0:\n",
        "                      y=j+abs(outputShape[2])\n",
        "                  else:\n",
        "                      y=j\n",
        "                      \n",
        "                  J[x,y]=nearestNeighboutInterp(pM,I)\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\"Error ! Still not implemented\")\n",
        "        \n",
        "    return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGcj3LTUOLsR"
      },
      "source": [
        "Let's test the inverse warping and compare it with the implementation of scipy. Test with at least 5 different transformation matrices (try different onfigurations).\n",
        "Be careful, the implementation of scipy works only with affine transformations.\n",
        "You can use other implementations from opencv or skimage (even for the projective transformations) if you want. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64_9y0HGegC1"
      },
      "source": [
        "T=Tmatrix(scale=(1,0.5), rotationAngle=45, shearAngles=(34,0),translation=(10,-5),elation=(0,0),reflection=(False,False))\n",
        "print('The transformation matrix T is:\\n', T)\n",
        "\n",
        "Xmi=InverseWarping(X,T,outputShape=None)\n",
        "#\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "ax1.imshow(X, cmap='gray')\n",
        "ax1.set_title('Source image')\n",
        "ax2.imshow(Xmi, cmap='gray')\n",
        "ax2.set_title('Inverse warped image')\n",
        "plt.show() \n",
        "\n",
        "\n",
        "\n",
        "# Only for affine transformations\n",
        "if T[2,0] ==0 and T[2,1] ==0:\n",
        "  J=scipy.ndimage.affine_transform(X, LA.inv(T),order=0)\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "  ax1 = plt.subplot(1, 2, 1)\n",
        "  ax2 = plt.subplot(1, 2, 2)\n",
        "  ax1.imshow(X, cmap='gray')\n",
        "  ax1.set_title('Source image')\n",
        "  ax2.imshow(J, cmap='gray')\n",
        "  ax2.set_title('Scipy transformed image')\n",
        "  plt.show() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG5ywBL5pCkE"
      },
      "source": [
        "**(OPTIONAL)** Implement the Lucas-Kanade Algorithm to register the source image to the target image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3kko3FYegN0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}