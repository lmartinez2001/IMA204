{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_ImageRegistration_LandmarkSSM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-FYoNLUWFgD"
      },
      "source": [
        "## Landmark based registration and Statistical Shape Analysis\n",
        "\n",
        "**Deadline**: Upload this notebook (rename it as 'TP-ImaReg-LandmarkSSM-YOUR-SURNAME.ipynb') on E-Campus before the deadline. No need to zip it.\n",
        "\n",
        "**Goal**: The goal of this notebook is to implement the algorithms seen today for landmarks based registration and statistical shape analysis. Please complete the code where you see **XXXXXXXXXXXXXX** and answer the questions.\n",
        "\n",
        "We will use the FEI dataset (https://fei.edu.br/~cet/facedatabase.html) which is composed of several facial images annotated with 68 landmarks (already estimated and placed). Below, you will find a picture with an example. People express two emotions, either neutral or happy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRzP1GaOmbJd"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='15vsAdMepHzdoZ3iqNS3kpI3KGW7D0vRs',\n",
        "dest_path='./data/Data_FEI.npz')\n",
        "gdd.download_file_from_google_drive(file_id='1ywQbf23-JoPklWCcH_mi5Nuw5BQskxvB',\n",
        "dest_path='./data/facial_landmarks_68markup.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPlaXGCAnEDY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzmzGn0SXuJF"
      },
      "source": [
        "Now, let's load the data. \n",
        "\n",
        "We have a list of images, the position of the landmarks (aligned to the images), the class labels Y (0 for neutral and 1 for happy) and the names of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ4CeDIRnEJ3"
      },
      "source": [
        "# Loading data\n",
        "Working_directory=\"./data/\" \n",
        "with np.load(Working_directory + 'Data_FEI.npz') as data:\n",
        "    Images=data['Images_FEI'] # list of images\n",
        "    Landmarks = data['Landmarks_FEI'] # original landmarks   \n",
        "    Y = data['Emotions_FEI'] # class, 0 for neutral and 1 for happy\n",
        "    Names = data['Names_FEI']    \n",
        "N,M = Landmarks.shape # number subjects \n",
        "dim = 2\n",
        "M = int(M/dim) # Number of landmarks (they are in 2D)\n",
        "print('Number of subjects:', N, '; Number of landmarks:',M) \n",
        "class_names = [\"neutral\",\"happy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFoTEUYUYVB3"
      },
      "source": [
        "Here, we show an example of facial landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEcPgo8htm7Z"
      },
      "source": [
        "# Plot the facial landmarks\n",
        "Example=plt.imread(Working_directory + './facial_landmarks_68markup.jpg') # function to read a jpg image\n",
        "plt.figure(figsize = (7,7)) # Size of the plot\n",
        "plt.imshow(Example)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "984DltRQYkcx"
      },
      "source": [
        "We randomly shuffle the data (even if it is not necessary for the TP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6x23pATnEHu"
      },
      "source": [
        "# Shuffle data randomly\n",
        "indeces=np.arange(N) # Integers from 0 to N-1\n",
        "np.random.shuffle(indeces)\n",
        "\n",
        "X=Landmarks[indeces]\n",
        "Yp=Y[indeces]\n",
        "Imagesp=Images[indeces]\n",
        "\n",
        "Namesp=[''] * N\n",
        "for i in range(0,N):\n",
        "    Namesp[i]=Names[indeces[i]] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txLbiIN3Yvad"
      },
      "source": [
        "and we plot the first 6 (random) images with their respective landmarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgOTH_Ju_5F"
      },
      "source": [
        "# plot the first 6 images of the data-set\n",
        "for i in range(0,6):\n",
        "    image = Imagesp[i,:,:]\n",
        "    plt.figure()\n",
        "    plt.imshow(image, cmap='gray', origin='upper')\n",
        "    landmark=X[i,:]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    plt.plot(x,y,'o')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk1MU2k3Y7YT"
      },
      "source": [
        "Now it's time to implement first the affine transformation and then the procrustes alignement (similarity transformation).\n",
        "Please complete the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wlGVRoYnhVf"
      },
      "source": [
        "def AffineRegistrationLandmarks(x,y):\n",
        "    \n",
        "    '''\n",
        "    Inputs: \n",
        "               x: [M,2] array containing the M 2-dim source landmarks\n",
        "               y: [M,2] array containing the M 2-dim target landmarks\n",
        "    \n",
        "    Outputs:\n",
        "               xp: [M,2] array containing the M 2-dim aligned source landmarks\n",
        "               T: [3,3] transformation matrix\n",
        "    \n",
        "    '''\n",
        "\n",
        "    if x.shape[0] != y.shape[0] or x.shape[1] != y.shape[1]:\n",
        "        raise NameError('data should have the same dimensions')\n",
        "        \n",
        "    if x.shape[1] != 2:\n",
        "        raise NameError('This code works only for 2 dimennsional data')        \n",
        "        \n",
        "    M=x.shape[0]\n",
        "\n",
        "    XXXXXXXXXXXXXXXX\n",
        "       \n",
        "    return xp,T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtF__k8eZlUy"
      },
      "source": [
        "Let's test your implementation and see if it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mklgjF8IZJ9G"
      },
      "source": [
        "# Choose two random indeces between 0 and N-1\n",
        "indexSource = XXXXXXXXXXXXXXXX\n",
        "indexTarget = XXXXXXXXXXXXXXXX\n",
        "\n",
        "# Choose if you want to plot data or not\n",
        "show_plot=1\n",
        "\n",
        "# Procrustes superimposition of two configurations    \n",
        "ls = X[indexSource] # source configuration\n",
        "Is = Imagesp[indexSource,:,:]\n",
        "lt = X[indexTarget] # target configuration\n",
        "It = Imagesp[indexTarget,:,:]\n",
        "\n",
        "# reshape landmarks configurations as matrices [M,2]\n",
        "xs=np.reshape(ls,(M,dim))\n",
        "xt=np.reshape(lt,(M,dim))\n",
        "\n",
        "xpA,TA=AffineRegistrationLandmarks(xs,xt)\n",
        "print(TA)\n",
        "\n",
        "if show_plot==1:\n",
        "    plt.figure()\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(xs[:,0], xs[:,1], c='r',label='original source') \n",
        "    plt.scatter(xt[:,0], xt[:,1], c='b',label='target')\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05)) \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.title('Original landmarks')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(xpA[:,0], xpA[:,1], c='g',label='aligned source') \n",
        "    plt.scatter(xt[:,0], xt[:,1], c='b',label='target')\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05)) \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.title('Affine alignement')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5-f5LDuZsrl"
      },
      "source": [
        "Now, let's implement the procrustes alignement following the inputs and rules explained in the header of the function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH9qOuh7wuk-"
      },
      "source": [
        "def procrustes_align(x,y,mode='best',verbose=1):\n",
        "\n",
        "    \"\"\" \n",
        "    Inputs: \n",
        "               X: [M,2] array containing the M 2-dim source landmarks\n",
        "               Y: [M,2] matrix containing the M 2-dim target landmarks\n",
        "               mode: 'rotation' to have only rotation, 'reflection' to\n",
        "                   have only reflection and 'best' to have the one decided by the\n",
        "                   data depending on det(U*V')\n",
        "               verbose: 1 to have explanations and 0 otherwise\n",
        "    \n",
        "    Outputs:\n",
        "               Xp: [M,2] array containing the aligned source landmarks\n",
        "               s: uniform scaling\n",
        "               R: rotation or reflection matrix\n",
        "               t: translation vector\n",
        "               SSR: sum of squared of residuals\n",
        "               ratio_SSR: ratio of SSR with respect to the initial SSR\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if mode.lower()!='best' and mode.lower()!='rotation' and mode.lower()!='reflection':\n",
        "        raise NameError('Error ! mode should be equal to best, rotation or reflection')   \n",
        "    \n",
        "    if x.shape[0] != y.shape[0] or x.shape[1] != y.shape[1]:\n",
        "        raise NameError('data should have the same dimensions')\n",
        "        \n",
        "    if x.shape[1] != 2:\n",
        "        raise NameError('This code works only for 2 dimennsional data')        \n",
        "        \n",
        "    M=x.shape[0]\n",
        "    \n",
        "    # Center data\n",
        "    XXXXXXXXXXXXXXXX\n",
        "    # Scale to equal unit size\n",
        "    XXXXXXXXXXXXXXXX\n",
        "        \n",
        "    # Optimal parameters (hint: use np.linalg.svd)\n",
        "    U, D, Vt = XXXXXXXXXXXXXXXX\n",
        "    \n",
        "    if mode.lower() == 'rotation':\n",
        "        if np.absolute(np.linalg.det(U @ Vt)-1)<1e-5: # det(R)==1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a rotation. Computing rotation.')               \n",
        "            S=np.eye(2) \n",
        "        elif np.absolute(np.linalg.det(U @ Vt)+1)<1e-5: # det(R)== -1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a reflection but a rotation is computed as requested.')               \n",
        "            S=np.array([[1, 0], [0, np.linalg.det(U@Vt)]]) # to have det(U*V')=1\n",
        "        else:\n",
        "            raise NameError('Error ! U*Vt should be an orthogonal matrix')\n",
        "    elif mode.lower() == 'reflection':\n",
        "        if np.absolute(np.linalg.det(U @ Vt)-1)<1e-5: # det(R)==1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a rotation but a reflection is computed as requested.')               \n",
        "            S=np.array([[1, 0], [0, -np.linalg.det(U@Vt)]]) # to have det(U*V')=-1\n",
        "        elif np.absolute(np.linalg.det(U @ Vt)+1)<1e-5: # det(R)== -1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a reflection. Computing reflection.')               \n",
        "            S=np.eye(2)\n",
        "        else:\n",
        "            raise NameError('Error ! U*Vt should be an orthogonal matrix')\n",
        "    elif mode.lower() == 'best':\n",
        "        if np.absolute(np.linalg.det(U @ Vt)-1)<1e-5: # det(R)==1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a rotation. Computing rotation.')               \n",
        "            S=np.eye(2)\n",
        "        elif np.absolute(np.linalg.det(U @ Vt)+1)<1e-5: # det(R)== -1\n",
        "            if verbose == 1:\n",
        "                print('The best R is a reflection. Computing reflection.')               \n",
        "            S=np.eye(2)\n",
        "        else:\n",
        "            raise NameError('Error ! U*Vt should be an orthogonal matrix')\n",
        "            \n",
        "    R=XXXXXXXXXXXXXXXX\n",
        "    s=XXXXXXXXXXXXXXXX\n",
        "    \n",
        "    if mode.lower() == 'rotation':\n",
        "        if np.absolute(np.linalg.det(R)-1)>1e-5:\n",
        "            raise NameError('Error ! there is a problem...')\n",
        "    if mode.lower() == 'reflection':\n",
        "        if np.absolute(np.linalg.det(R)+1)>1e-5:\n",
        "            raise NameError('Error ! there is a problem...')\n",
        "            \n",
        "    t = XXXXXXXXXXXXXXXX\n",
        "    xp = XXXXXXXXXXXXXXXX\n",
        "    \n",
        "    # Procrustes residuals\n",
        "    SSR = np.sum(np.power((y-xp),2))\n",
        "    \n",
        "    # Ratio with initial residual\n",
        "    SSR0 = np.sum(np.power((y-x),2))\n",
        "    ratioSSR = SSR*100/SSR0\n",
        "    \n",
        "    return xp, s, R, t, SSR, ratioSSR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4UI26Kbwf7l"
      },
      "source": [
        "xp, s, R, t, SSR, ratioSSR = procrustes_align(xs,xt)\n",
        "\n",
        "if show_plot==1:\n",
        "    plt.figure()\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(xs[:,0], xs[:,1], c='r',label='original source') \n",
        "    plt.scatter(xt[:,0], xt[:,1], c='b',label='target')\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05)) \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.title('Original landmarks')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(xp[:,0], xp[:,1], c='g',label='aligned source') \n",
        "    plt.scatter(xt[:,0], xt[:,1], c='b',label='target')\n",
        "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05)) \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.title('Procrustes alignement')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2L1bJ-kDyen"
      },
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "*   What happens if you center the configurations before the alignment ?\n",
        "*   When do you expect a perfect alignment ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGW2w2yKa2_y"
      },
      "source": [
        "Now, using the functions implemented in the previous jupyter-notebook apply the transformation computed with the affine and/or procrustes alignement to the source image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8wIrVhZyFGn"
      },
      "source": [
        "def nearestNeighboutInterp(pM,I,coords=None):\n",
        "  XXXXXXXXXXXXXXXX\n",
        "\n",
        "def InverseWarping(I,T,coords=None,outputShape=None):\n",
        "    XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qga8xbAlyKzc"
      },
      "source": [
        "def applyTransformation(T, points=None, coords=None):\n",
        "   XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZrI1uZyViN"
      },
      "source": [
        "# compute T       \n",
        "T = np.array([\n",
        "            [s*R[0,0], s*R[0,1], t[0]],\n",
        "            [s*R[1,0], s*R[1,1], t[1]],\n",
        "            [0, 0, 1]\n",
        "            ])\n",
        "    \n",
        "Ism=InverseWarping(Is,T,outputShape=None)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 15))\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "ax3 = plt.subplot(1, 3, 3)\n",
        "ax1.imshow(Is, cmap='gray')\n",
        "ax1.set_title('Source image')\n",
        "ax2.imshow(Ism, cmap='gray')\n",
        "ax2.set_title('Transformed source image')\n",
        "ax3.imshow(It, cmap='gray')\n",
        "ax3.set_title('Target image')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piXhw724CMGG"
      },
      "source": [
        "Now let's implement the Generalized Procrustes Analysis (GPA) using the previously implemented procrustes alignement function.\n",
        "\n",
        "As before, please follow the inputs and rules explained in the header of the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWXkB2I1C2LP"
      },
      "source": [
        "def generalized_procrustes_analysis(X,tau=1e-5,tangent=1):\n",
        "  \"\"\"\n",
        "  Inputs: \n",
        "            X: [N,2M] array containing N configurations of 2D landmarks. \n",
        "               Each configuration has M landmarks\n",
        "            tau: parameter for the stopping criteria (please refer to the slides \n",
        "                 of the course)\n",
        "            tangent: if set to 1, data will be projected onto the tangent space\n",
        "\n",
        "  Outputs: \n",
        "            Xm1: [M,2] array containing the landmarks of the average configuration\n",
        "            Xcp: [N,2M] array containing the aligned landmarks onto Xm1\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if X.shape[1] % 2 != 0:\n",
        "        raise NameError('This code works only for 2 dimennsional data')        \n",
        "          \n",
        "  # Parameters\n",
        "  N,M=X.shape\n",
        "  dim=2\n",
        "  M=int(M/dim)\n",
        "\n",
        "  # Plot original data\n",
        "  plt.figure()    \n",
        "  for i in range(0,N):\n",
        "      landmark=X[i]\n",
        "      x=landmark[::2]\n",
        "      y=landmark[1::2]        \n",
        "      plt.scatter(x, y, c='r') \n",
        "  plt.gca().invert_yaxis()     \n",
        "  plt.title('Original landmarks')\n",
        "\n",
        "\n",
        "  # Center each configuration\n",
        "  Xc=np.zeros((N,M*dim))\n",
        "  for i in range(0,N):\n",
        "      XXXXXXXXXXXXXXXX\n",
        "      \n",
        "  # Compute first average configuration\n",
        "  Xm0=XXXXXXXXXXXXXXXX\n",
        "\n",
        "  # Plot configurations and first average    \n",
        "  plt.figure()    \n",
        "  for i in range(0,N):\n",
        "      landmark=Xc[i]\n",
        "      x=landmark[::2]\n",
        "      y=landmark[1::2]        \n",
        "      plt.scatter(x, y, c='r')       \n",
        "  plt.scatter(Xm0[::2],Xm0[1::2],c='g',label='average')    \n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
        "  plt.gca().invert_yaxis() \n",
        "  plt.title('Centered data with first average') \n",
        "\n",
        "  # Normalize average\n",
        "  XXXXXXXXXXXXXXXX\n",
        "\n",
        "  # Procrustes alignement of all configurations to the average Xm0\n",
        "  Xcp=np.zeros((N,M*dim))\n",
        "  for i in range(0,N):\n",
        "      XXXXXXXXXXXXXXXX\n",
        "      \n",
        "  # Reshape average as vector\n",
        "  Xm0=XXXXXXXXXXXXXXXX\n",
        "      \n",
        "  # Plot configurations and average    \n",
        "  plt.figure()    \n",
        "  for i in range(0,N):\n",
        "      landmark=Xcp[i]\n",
        "      x=landmark[::2]\n",
        "      y=landmark[1::2]        \n",
        "      plt.scatter(x, y, c='r') \n",
        "  plt.scatter(Xm0[::2],Xm0[1::2],c='g',label='average')  \n",
        "  plt.gca().invert_yaxis()   \n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
        "  plt.title('Aligned data to normalized initial mean')    \n",
        "\n",
        "  # Tangent space projection\n",
        "  if tangent==1:\n",
        "      # landmarks after tangent space projection\n",
        "      Xcpt=np.zeros((N,M*dim))\n",
        "      # vector measuring the difference before/after projection\n",
        "      diff = np.zeros((N,1))\n",
        "      \n",
        "      for i in range(0,N):\n",
        "          Xcpt[i]=XXXXXXXXXXXXXXXX\n",
        "          diff[i]=XXXXXXXXXXXXXXXX\n",
        "          \n",
        "      # we look for the subject with the maximum difference before/after projection    \n",
        "      ind=np.argmax(diff)\n",
        "          \n",
        "      # Plot configurations and first average\n",
        "      plt.figure()\n",
        "      l=Xcp[ind]\n",
        "      lt=Xcpt[ind]\n",
        "      plt.scatter(l[::2], l[1::2], c='r', label='before projection')  \n",
        "      plt.scatter(lt[::2], lt[1::2], c='b', label='after projection') \n",
        "      plt.gca().invert_yaxis() \n",
        "      plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
        "      plt.title('Subject with maximum variation')        \n",
        "\n",
        "      plt.figure()\n",
        "      for i in range(0,N):\n",
        "          landmark=Xcp[i]\n",
        "          x=landmark[::2]\n",
        "          y=landmark[1::2]        \n",
        "          if i==ind:\n",
        "              plt.scatter(x, y, c='b',label='Subject with max distortion', zorder=10)\n",
        "          else:\n",
        "              plt.scatter(x, y, c='r')\n",
        "              \n",
        "      plt.scatter(Xm0[::2],Xm0[1::2],c='g',label='average', zorder=5)   \n",
        "      plt.gca().invert_yaxis()  \n",
        "      plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
        "      plt.title('Subjects before projection')  \n",
        "      \n",
        "      Xcp=Xcpt\n",
        "\n",
        "  # Re-estimate average configuration\n",
        "  Xm1=XXXXXXXXXXXXXXXX\n",
        "\n",
        "  # Procrustes alignement of Xm1 to Xm0 \n",
        "  Xm1, s, R, t, SSR, ratioSSR = procrustes_align(np.reshape(Xm1,(M,dim)) ,np.reshape(Xm0,(M,dim)),'best',0)\n",
        "\n",
        "  # Normalize new average Xm1 \n",
        "  XXXXXXXXXXXXXXXX\n",
        "  Xm1 = XXXXXXXXXXXXXXXX\n",
        "\n",
        "  # Reshape average as vector\n",
        "  Xm1=XXXXXXXXXXXXXXXX\n",
        "\n",
        "  # Plot configurations and new average    \n",
        "  plt.figure()    \n",
        "  for i in range(0,N):\n",
        "      landmark=Xcp[i]\n",
        "      x=landmark[::2]\n",
        "      y=landmark[1::2]        \n",
        "      plt.scatter(x, y, c='r') \n",
        "  plt.scatter(Xm1[::2],Xm1[1::2],c='g',label='average')   \n",
        "  plt.gca().invert_yaxis()  \n",
        "  plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
        "  plt.title('Aligned data to new mean')   \n",
        "\n",
        "\n",
        "  itera=1    \n",
        "  while np.sqrt(np.dot((Xm0-Xm1),(Xm0-Xm1))) > tau:\n",
        "      print('Iter number %d , Error: %f' % (itera, np.sqrt(np.dot((Xm0-Xm1),(Xm0-Xm1))) ) )\n",
        "      itera=itera+1\n",
        "      \n",
        "      # Update Xm0 to Xm1\n",
        "      Xm0=Xm1\n",
        "      \n",
        "      # Procrustes alignement of all configurations to the average Xm0        \n",
        "      for i in range(0,N):\n",
        "          temp=np.reshape(Xc[i],(M,dim))\n",
        "          xp, s, R, t, SSR, ratioSSR = procrustes_align(temp,np.reshape(Xm0,(M,dim)),'best',0)\n",
        "          Xcp[i]=np.reshape(xp,(M*dim))\n",
        "          \n",
        "      # Tangent space projection\n",
        "      if tangent==1:                  \n",
        "          for i in range(0,N):\n",
        "              Xcp[i]=XXXXXXXXXXXXXXXX                \n",
        "      \n",
        "      # Re-estimate average configuration\n",
        "      Xm1=XXXXXXXXXXXXXXXX\n",
        "      \n",
        "      # Procrustes alignement of Xm1 to Xm0 \n",
        "      Xm1, s, R, t, SSR, ratioSSR = procrustes_align(np.reshape(Xm1,(M,dim)),np.reshape(Xm0,(M,dim)),'best',0)\n",
        "      \n",
        "      # Normalize new average Xm1 \n",
        "      XXXXXXXXXXXXXXXX\n",
        "      Xm1 = XXXXXXXXXXXXXXXX\n",
        "      \n",
        "      # Reshape average as vector\n",
        "      Xm1=np.reshape(Xm1,(M*dim))\n",
        "      \n",
        "      # Plot configurations and new average    \n",
        "      plt.figure()    \n",
        "      for i in range(0,N):\n",
        "          landmark=Xcp[i]\n",
        "          x=landmark[::2]\n",
        "          y=landmark[1::2]        \n",
        "          plt.scatter(x, y, c='r') \n",
        "      plt.scatter(Xm1[::2],Xm1[1::2],c='g',label='average')  \n",
        "      plt.gca().invert_yaxis()   \n",
        "      plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
        "      plt.title('GPA results after iter %i' % itera)\n",
        "      \n",
        "\n",
        "  return Xcp, Xm1 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdYVObB5D_Az"
      },
      "source": [
        "Let's test your implementation and see if it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgGbJjbZFOkD"
      },
      "source": [
        "#  GPA (Generalized Procrustes Analysis)\n",
        "Xcp, Xm1  = generalized_procrustes_analysis(X)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVZ3pK4wFPGg"
      },
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "\n",
        "*   Try not to project the data onto the tangent space (i.e. `tangent=0`). Do the results vary ? Why in your opinion ? Hint: Look at the variability of the original data...\n",
        "*   Do the following four triangles have the same shape ? Explain why ?\n",
        "\n",
        "![shape.png](https://drive.google.com/uc?id=10OSJUfNDJ1xw6H3sRu7l3LRoojxju_4L)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhtc1t8obVY"
      },
      "source": [
        "Let's compute the shape variability using PCA. You will compute the three modes of deformations, as described in the slides of the lecture, at $\\pm 3 \\sigma$, where $\\sigma$ is the standard deviation thus the square root of the the relative eigenvalue "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYw9HlINaRqS"
      },
      "source": [
        "#%% Shape variability analysis\n",
        "# we will use the scikit-learn implementation for PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA\n",
        "pca = PCA(random_state=1) # by fixing the random_state we are sure that results are always the same\n",
        "Y=pca.fit_transform(Xcp)\n",
        "U=pca.components_.T # we want PC on columns\n",
        "D = (pca.singular_values_)**2/(X.shape[0]-1) # computation of the eigenvalues\n",
        "var_explained = pca.explained_variance_ratio_*100 # variance explained\n",
        "\n",
        "print('The first three modes explain %f, %f and %f of the total variability respectively' % (var_explained[0], var_explained[1], var_explained[2]))\n",
        "\n",
        "# Compute first mode\n",
        "first_mode_m= XXXXXXXXXXXXXXXX\n",
        "first_mode_p= XXXXXXXXXXXXXXXX\n",
        "# Compute second mode\n",
        "second_mode_m= XXXXXXXXXXXXXXXX\n",
        "second_mode_p= XXXXXXXXXXXXXXXX\n",
        "# Compute third mode\n",
        "third_mode_m= XXXXXXXXXXXXXXXX\n",
        "third_mode_p= XXXXXXXXXXXXXXXX\n",
        "\n",
        "if show_plot==1:\n",
        "    plt.figure()\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.scatter(first_mode_m[::2], first_mode_m[1::2], c='r') \n",
        "    plt.xlabel('- 3 std')\n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.scatter(Xm1[::2], Xm1[1::2], c='g')\n",
        "    plt.xlabel('average') \n",
        "    plt.title('First mode of deformation') \n",
        "    plt.gca().invert_yaxis()    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.scatter(first_mode_p[::2], first_mode_p[1::2], c='r')\n",
        "    plt.xlabel('+ 3 std') \n",
        "    plt.gca().invert_yaxis() \n",
        "    \n",
        "    plt.figure()\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.scatter(second_mode_m[::2], second_mode_m[1::2], c='r') \n",
        "    plt.xlabel('- 3 std') \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.scatter(Xm1[::2], Xm1[1::2], c='g')\n",
        "    plt.xlabel('average') \n",
        "    plt.title('Second mode of deformation')    \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.scatter(second_mode_p[::2], second_mode_p[1::2], c='r')\n",
        "    plt.xlabel('+ 3 std') \n",
        "    plt.gca().invert_yaxis() \n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.scatter(third_mode_m[::2], third_mode_m[1::2], c='r') \n",
        "    plt.xlabel('- 3 std') \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.scatter(Xm1[::2], Xm1[1::2], c='g')\n",
        "    plt.xlabel('average') \n",
        "    plt.title('Third mode of deformation')    \n",
        "    plt.gca().invert_yaxis() \n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.scatter(third_mode_p[::2], third_mode_p[1::2], c='r')\n",
        "    plt.xlabel('+ 3 std') \n",
        "    plt.gca().invert_yaxis() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1qdvv6upyNC"
      },
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "\n",
        "*   How many modes do you need to explain 90% of the variability ?\n",
        "*   Which anatomical variability do the first three modes show ? Was it expected ?\n",
        "*   How could you check whether they show an anatomically plausible deformation ? \n",
        "*   Let's say that the anatomical deformation is not anatomically plausible, which kind of deformation would you use instead ? Why ?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oQHj9Q5Hz8j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}